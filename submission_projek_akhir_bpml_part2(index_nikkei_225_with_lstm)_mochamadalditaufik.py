# -*- coding: utf-8 -*-
"""Submission Projek Akhir BPML Part2(Index Nikkei 225 with LSTM)_MochamadAldiTaufik

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1H1qZYKhaBlDVFBonOXn0F90CL9_kgEnx

#SUBMISSION Index Nikkei 225 Prediction With LSTM Model

NAME : MOCHAMAD ALDI TAUFIK

E-MAIL : alditaufik137@gmail.com

KELAS : BELAJAR PENGEMBANGAN MACHINE LEARNING

DATASET: https://finance.yahoo.com/quote/%5EN225?p=%5EN225

# **IMPORT LIBRARY**
"""

#library preprocessing
import numpy as np # library untuk mengubah gambar menjadi array
import pandas as pd # library untuk mengolah data tabel
from sklearn.preprocessing import MinMaxScaler # library untuk normalisasi
import zipfile, os # library untuk mendownload zipfile

#library visualisasi
import matplotlib.pyplot as plt # Library untuk visualisai plot
import seaborn as sns # Library untuk visualisai plot lebih bagus

#library model
import tensorflow as tf # library machine learning dari google untuk memproses dataset
from tensorflow.keras.optimizers import RMSprop # Mengimport optimizer untuk model
from keras.callbacks import ModelCheckpoint # Callback untuk menyimpan model
import keras.backend as K # Untuk membuat fungsi R2 Keras

#library perhitungan
from sklearn.metrics import mean_squared_error # Untuk menggunakan loss mean squared error pada model
from sklearn.metrics import r2_score # Untuk menghitung koefisien determinasi

"""#**Import Dataset**
Mendownload Dataset Index Nikkei 225 yang diambil dari Yahoo! finance https://finance.yahoo.com/quote/%5EN225?p=^N225 dan telah dimasukkan ke dalam Dropbox

Indeks Nikkei 225 merupakan indeks utama di bursa Tokyo dan dipandang sebagai salah satu barometer penting perekonomian dan pasar saham Jepang. Indeks Nikkei disebut-sebut sama seperti indeks Dow Jones. Indeks ini merupakan indeks tertua di kawasan Asia yang mulai muncul sekitar pada tahun 1950. indeks Nikkei diciptakan oleh surat kabar ekonomi Jepang Nihon Keizai Shimbun.
"""

# Mendownload dataset menggunakan wget

!wget --no-check-certificate \
  https://dl.dropbox.com/s/vsbkkbr52qg3bkr/N225.zip?dl=0 \
  -O /tmp/N225.zip

"""# **Data Prepocessing**"""

# Mengekstrak folder zip yang telah terdownload
local_zip = '/tmp/N225.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp')
zip_ref.close()
 
base_dir = '/tmp/N225'

df = pd.read_csv('/tmp/N225.csv')
print(df.shape)
print(df.dtypes)

"""Menampilkan 5 Data teratas dari table"""

df.head()

"""Menampilkan 5 Data terbawah dari table"""

df.tail()

# Melihat informasi dari table dan terdapat 14.317 sample
df.info()

# Melihat jumlah sampel yang NAN (tidak ada nilainya)
df.isna().sum()

# Menghapus sample NaN
df=df.dropna()
print(df)
print(df.shape)

# Merubah tipe data kolom 'Date' menjadi 'datetime'
df['Date'] = pd.to_datetime(df['Date'])
df.head()

"""#**Visualisasi data Index Nikkei 225**
Menampilkan keseluruhan harga pembukaan Nikkei 225 dengan plot visualisasi agar dapat dimengerti oleh orang pembaca


"""

# Menampilkan visualisasi menggunakan matplotlib dan seaborn
plt.figure(figsize=(15,7))
sns.set(style="whitegrid")
plt.title('Harga Open Index Nikkei 225 per Tahun')
sns.lineplot(data=df['Open'], label='Open',color='skyblue')

# Membuat variabel duplikat yang akan digunakan untuk preprocessing
df2=df.copy()
df2.shape

"""#**Pembagian Data Train dan Data Test**
Membagi Dataset dengan rasio 80% Data Train dan 20% Data Test

"""

df2.reset_index(drop=True,inplace=True)
df_train = df2.loc[:int(df2.shape[0]*0.8),:]
df_test = df2.loc[int(df2.shape[0]*0.8):,:]
df2.shape

df_train.shape

df_test.shape

# Menampilkan pembagian dataset dengan plot visualisasi
plt.figure(figsize=(15,7))
sns.set(style="whitegrid")
plt.title('Data train vs Data test')
sns.lineplot(data=df_train['Open'], label='train',color='skyblue')
sns.lineplot(data=df_test['Open'], label='test',color='plum')

df_train

df_test

"""Agar dapat diproses oleh model, kita perlu mengubah nilai-nilai dari dataframe ke dalam tipe data numpy array menggunakan atribut values.


"""

# Mengubah nilai kolom 'Open' pada DataFrame ke dalam tipe data numpy array
training_set = df2.iloc[:, 1:2].values
training_set

"""#**Feature Scaling**
Melakukan feature scaling yaitu suatu cara untuk membuat numerical data pada dataset memiliki rentang nilai (scale) yang sama. Biasa disebut juga normalisasi


"""

# Menormalisasikan nilai sample menjadi nilai dengan rentang 0 sampai 1 untuk dimasukkan ke dalam model
sc = MinMaxScaler(feature_range = (0, 1))
training_set_scaled = sc.fit_transform(training_set)
training_set_scaled

"""#**Pembuatan Struktur Data**"""

# Membuat data struktur dengan 60 selisih waktu and 1 output
X_train = []
y_train = []
for i in range(60, 11122):
    X_train.append(training_set_scaled[i-60:i, 0])  # Struktur untuk X_train
    y_train.append(training_set_scaled[i, 0])       # Struktur untuk y_train
X_train, y_train = np.array(X_train), np.array(y_train)
print(len(X_train))
print(len(y_train))

# Reshaping data ke nilai 0 sampai 1
X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))
X_train

len(X_train)

# Membuat kelas dan fungsi agar proses training berhenti saat Koefisien Determinasi model telah mencapai 98%
class myCallBack(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('r2_keras') >= 0.90):
      print("\nKoefisien Determinasi telah mencapai > 90%!")
      self.model.stop_training = True
myCallBack = myCallBack()
# Fungsi untuk menyimpan model
save_direc = os.path.join(os.getcwd(), '/content/sample_data')

model_name = 'Nikkei-LSTM_weight_model.h5'

# Membuat directory untuk menyimpan model
if not os.path.isdir(save_direc):
    os.makedirs(save_direc)

# Menggabungkan directory dengan model
modelpath = os.path.join(save_direc, model_name)

checkpoint = ModelCheckpoint(filepath = modelpath, monitor = 'mae', verbose = 1, save_best_only = True, 
                             save_weights_only = True, period=1)

"""Koefisien determinasi digunakan sebagai informasi mengenai kecocokan suatu model dan dihitung untuk mengetahui sejauh mana kecocokan sejumlah variabel bebas yang ada dalam sebuah model persamaan regresi linier berganda secara berbarengan mampu menjelaskan variabel tidak bebasnya.

Nilai koefisien determinasi sendiri berada di rentang nol sampai satu. Suatu nilai ini bisa dikatakan ‘baik’ jika ia berada di atas angka 0,5, sebaliknya suatu nilai koefisien determinasi dibilang ‘tidak baik’ jika di bawah 0,5.
"""

# Membuat fungsi untuk koefisien determinasi yang akan digunakan ke dalam model
def r2_keras(y_true, y_pred):
    SS_res =  K.sum(K.square( y_true - y_pred ))
    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )
    return ( 1 - SS_res/(SS_tot + K.epsilon()) )

"""Arsitektur model menggunakan 4 layer LSTM dengan dimensi sebesar 50 pada masing-masing layer, serta 0.2/20% dropout pada setiap layer LSTM agar model tidak overfitting.


"""

model = tf.keras.models.Sequential([
  tf.keras.layers.LSTM(50, return_sequences=True, input_shape = (X_train.shape[1], 1)), # Menambahkan layer LSTM pertama
  tf.keras.layers.Dropout(0.2), # Menggunakan dropout agar model tidak overfitting
  tf.keras.layers.LSTM(50, return_sequences=True), # Menambahkan layer LSTM kedua
  tf.keras.layers.Dropout(0.2), # Menggunakan dropout agar model tidak overfitting
  tf.keras.layers.LSTM(50, return_sequences=True), # Menambahkan layer LSTM ketiga
  tf.keras.layers.Dropout(0.2), # Menggunakan dropout agar model tidak overfitting
  tf.keras.layers.LSTM(50), # Menambahkan layer LSTM keempat
  tf.keras.layers.Dropout(0.2), # Menggunakan dropout agar model tidak overfitting
  tf.keras.layers.Dense(1), # Outputnya adalah 1 
])
model.summary() # Melihat shape dan parameter model

model.compile(loss='mean_squared_error', optimizer=RMSprop(learning_rate=0.001), # Menggunakan optimizer RMSprop dengan learning rate 0.001
              metrics=[r2_keras, 'mae']) # Menggunakan metric r2 dan mae
# Proses Training Model LSTM
history = model.fit(X_train, y_train, epochs = 100, 
                    batch_size = 128, callbacks=[myCallBack, checkpoint], verbose = 1)

# Menampilkan plot loss dari model
plt.plot(history.history['loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.legend('loss')
plt.show()
# Menampilkan plot mae dari model
plt.plot(history.history['mae'])
plt.title('Model MAE')
plt.ylabel('MAE')
plt.xlabel('Epochs')
plt.legend('mae')
plt.show()

"""#**Prediksi Model LSTM**
Untuk membuktikan model LSTM bagus atau tidak, maka saya berinsiatif untuk melakukan prediksi terhadap data test dan train


"""

# Melakukan duplikasi pada Dataset test dan train dan mengubah menjadi numpy array 
dataset_test = df_test.copy()
dataset_train = df_train.copy()
real_stock_price = dataset_test.iloc[:, 1:2].values
real_stock_price1 = dataset_train.iloc[60:, 1:2].values
dataset_total = pd.concat((df_train['Open'], dataset_test['Open']), axis = 0)
inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values
inputs = inputs.reshape(-1,1)
inputs = sc.transform(inputs)

print('Panjang data total :', len(dataset_total))
print('Panjang data test :', len(dataset_test))
print('Panjang data train :', len(df_train))

inputs1 = df_train.Open.values
inputs1 = inputs1.reshape(-1,1)
inputs1 = sc.transform(inputs1)

print(len(inputs))
print(len(inputs1))

"""Memasukkan nilai dari data test ke dalam X_test dan data train ke dalam X_test1 lalu mereshape nilai tersebut ke dalam nilai dari 0 sampai 1


"""

X_test = []
for i in range(60, 2841):
    X_test.append(inputs[i-60:i, 0])
X_test = np.array(X_test)
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))

X_test1 = []
for i in range(60,11122):
    X_test1.append(inputs1[i-60:i, 0])
X_test1 = np.array(X_test1)
X_test1 = np.reshape(X_test1, (X_test1.shape[0], X_test1.shape[1], 1))

print(len(X_test))
print(len(X_test1))

# Menggunakan model untuk memprediksi nilai data test
predicted_stock_price = model.predict(X_test)
predicted_stock_price = sc.inverse_transform(predicted_stock_price)
predicted_stock_price

# Menggunakan model untuk memprediksi nilai data train
predicted_stock_price1 = model.predict(X_test1)
predicted_stock_price1 = sc.inverse_transform(predicted_stock_price1)
predicted_stock_price1

print('Dimensi real data test :', real_stock_price.shape)
print('Dimensi prediksi data test :', predicted_stock_price.shape)
print('Dimensi real data train :', real_stock_price1.shape)
print('Dimensi prediksi data train :', predicted_stock_price1.shape)

# Memasukkan nilai asli data test dan prediksinya ke dalam dataframe
pred = pd.DataFrame(list(zip(predicted_stock_price,real_stock_price)), 
                  columns = ('Predict','Real'))
pred.head()

# Memasukkan nilai asli data train dan prediksinya ke dalam dataframe
pred1 = pd.DataFrame(list(zip(predicted_stock_price1,real_stock_price1)), 
                  columns = ('Predict','Real'))
pred1.head()

"""#**Evaluasi Model**
Evaluasi model menggunakan Mean Absolute Error dan Mean Absolute Percentage Error


"""

# Membuat fungsi untuk MAPE dan MAE
def mape(y_true, y_pred):
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100

def mae(y_true, y_pred):
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.mean(np.abs((y_true - y_pred) / y_true))
print('Nilai Koefisien Determinasi terhadap Data Test\nR2: ',r2_score(predicted_stock_price,real_stock_price),'\n')

mape1 = mae(predicted_stock_price,real_stock_price)
print('Nilai Mean Absolute Error Prediksi terhadap Data Test\nMAPE: ' "{:.2f}".format(mape1),'\n')

mape2 = mape(predicted_stock_price,real_stock_price)
print('Nilai Mean Absolute Percentage Error Prediksi terhadap Data Test\nMAPE: ' "{:.2f}".format(mape2)+'%')

print('Nilai Koefisien Determinasi terhadap Data Train\nR2: ',r2_score(predicted_stock_price1,real_stock_price1),'\n')

mape1 = mae(predicted_stock_price1,real_stock_price1)
print('Nilai Mean Absolute Error Prediksi terhadap Data Train\nMAPE: ' "{:.2f}".format(mape1),'\n')

mape2 = mape(predicted_stock_price1,real_stock_price1)
print('Nilai Mean Percentage Error Prediksi terhadap Data Train\nMAPE: ' "{:.2f}".format(mape2)+'%')

"""#**Visualisasi Hasil Prediksi Model**
Membuat visualisasi dengan diagram pencar dan diagram garis untuk memudahkan pembaca untuk melihat hasil prediksi




"""

# Membuat diagram pencar untuk memperlihatkan ke akuratan hasil prediksi dan nilai real pada dataset
# Data prediksi vs data test

plt.figure(figsize=(15,7))
plt.scatter(x=predicted_stock_price,y=real_stock_price,s=3,color='limegreen')
plt.xlabel('predictions',fontsize=18)
plt.ylabel('real',fontsize=18)
plt.title('Data prediksi vs data test',fontsize=20)
plt.show()

# Membuat diagram pencar untuk memperlihatkan ke akuratan hasil prediksi dan nilai real pada dataset
# Data prediksi vs data train

plt.figure(figsize=(15,7))
plt.scatter(x=predicted_stock_price1,y=real_stock_price1,s=3,color='limegreen')
plt.xlabel('predictions',fontsize=18)
plt.ylabel('real',fontsize=18)
plt.title('Data prediksi vs data train',fontsize=20)
plt.show()

# Membuat diagram garis untuk memperlihatkan ke akuratan hasil prediksi dan nilai real pada dataset
# Data prediksi vs data train

plt.figure(figsize=(15,7))
plt.plot(real_stock_price1, color = 'palevioletred', label = 'Real Harga Index Nikkei 225')
plt.plot(predicted_stock_price1, color = 'limegreen', label = 'Prediksi Harga Index Nikkei 225')
plt.title('Prediksi Index Nikkei 225 vs Data Test',fontsize = 16)
plt.xlabel('Time')
plt.ylabel('Nikkei 225 Stock Price')
plt.legend()
plt.show()